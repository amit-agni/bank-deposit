{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Bank Term Deposits - Data Preparation"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   }
  },
  {
   "source": [
    "## Import Packages and Load Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn.impute\n",
    "from sklearn.preprocessing import OrdinalEncoder,OneHotEncoder,StandardScaler,FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "from project_utils import *\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "# %matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "data = pd.read_csv('../data/bank-additional/bank-additional-full.csv',sep=';')\n",
    "\n",
    "dp_dropCols(data,\"duration\")\n",
    "\n",
    "#Convert target to y=1 and n=0 and rename columun\n",
    "data[\"y\"][data[\"y\"] == 'yes'] = 1\n",
    "data[\"y\"][data[\"y\"] == 'no'] = 0\n",
    "data.rename(columns={\"y\":\"target\"}, inplace = True)\n",
    "data[\"target\"] = data[\"target\"].astype('int64')\n",
    "\n",
    "\n",
    "train_set, test_set = train_test_split(data, test_size=0.2,random_state=42,stratify = data[\"target\"],shuffle = True)\n",
    "\n",
    "countsAndProportions(data[\"target\"])\n",
    "countsAndProportions(test_set[\"target\"])\n",
    "countsAndProportions(train_set[\"target\"])\n",
    "\n",
    "train_set_X = train_set.drop(\"target\", axis=1)\n",
    "train_set_Y = train_set[\"target\"]\n",
    "\n",
    "test_set_X = test_set.drop(\"target\", axis=1)\n",
    "test_set_Y = test_set[\"target\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error #avoid cell execution\n",
    "\n",
    "#The imputer stores the median values in **statistics_** instance variable. We cannot be sure that there wonâ€™t be any missing values in new data after the system goes live, so it is safer to apply the imputer to all the numerical attributes\n",
    "data = dp_ImputeNumericCols(data)\n",
    "\n",
    "#Encode education as ordinal encoder and see if its inherent ordering property would lead to better results\n",
    "cols = [\"education\"]\n",
    "data = dp_EncodeOrdinalCols(data,cols,categories = [['illiterate','basic.4y','basic.6y','basic.9y','high.school','professional.course','university.degree','unknown']])\n",
    "\n",
    "cols = data.select_dtypes(include=\"object\").columns\n",
    "enc = DataframeOneHotEncoder(cols)\n",
    "data = enc.transform(data)    \n",
    "\n",
    "standardiseCols = ['age', 'campaign', 'pdays', 'previous','emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m','nr.employed']\n",
    "data = dp_StandardiseNumericCols(data,standardiseCols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_OrdinalEncode = [\"education\"]\n",
    "cols_OHE = data.select_dtypes(include=\"object\").columns\n",
    "cols_log1p = [\"age\"]\n",
    "cols_Numeric = ['campaign', 'pdays', 'previous','emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m','nr.employed']\n",
    "\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "#For OrdinalEncoder, the categories have to be a list of arrays (per column). Since we have only one column\n",
    "('oe', OrdinalEncoder(categories = [['illiterate','basic.4y','basic.6y','basic.9y','high.school','professional.course','university.degree','unknown']]),\n",
    "         cols_OrdinalEncode),\n",
    "('ohe', OneHotEncoder(sparse=False,handle_unknown=\"ignore\"),cols_OHE),\n",
    "('logAge',FunctionTransformer(np.log1p),cols_log1p),\n",
    "('std', StandardScaler(),cols_Numeric)\n",
    "])\n",
    "\n",
    "#Separate fit and transform, otherwise OHE was giving error as one of the categories were missing in Test\n",
    "full_pipeline.fit(train_set_X)\n",
    "train_prep = full_pipeline.transform(train_set_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# param_grid = [{'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},{'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},]\n",
    "param_grid = [{'n_estimators': [5, 10]},]\n",
    "\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(),param_grid, cv=5,scoring='f1',return_train_score=True)\n",
    "random_search.fit(train_prep,train_set_Y)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = full_pipeline.named_transformers_[\"ohe\"]\n",
    "# list(x.categories_)\n",
    "# random_search.best_estimator_.feature_importances_\n",
    "\n",
    "full_pipeline.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error #avoid cell execution\n",
    "\n",
    "### \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "modelTrainPredict(LogisticRegression(),train_prep,train_set_Y,test_set_X,test_set_Y)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "modelTrainPredict(DecisionTreeClassifier(),train_prep,train_set_Y,test_set_X,test_set_Y)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelTrainPredict(RandomForestClassifier(),train_prep,train_set_Y,test_set_X,test_set_Y)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "modelTrainPredict(MLPClassifier(),train_prep,train_set_Y,test_set_X,test_set_Y)\n",
    "\n",
    "### Cross Validation - Example\n",
    " \n",
    "from sklearn.model_selection import cross_val_score\n",
    "#sorted(sklearn.metrics.SCORERS.keys())\n",
    "scores = cross_val_score(DecisionTreeClassifier(), train_prep, train_set_Y,scoring=\"f1\", cv=10)\n",
    "scores\n",
    "\n",
    "\n"
   ]
  }
 ]
}